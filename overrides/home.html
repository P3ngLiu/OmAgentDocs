{#- This file was automatically generated - do not edit -#} {% extends
"main.html" %} {% block tabs %} {{ super() }}
<style>
  .md-header {
    position: initial;
    background-color: #001831;
  }
  .md-main__inner {
    margin: 0;
  }
  .md-content {
    display: none;
  }
  .md-tabs {
    background-color: #001831;
  }
  .md-header__option {
    display: none;
  }
  .md-search {
    display: none;
  }
  .md-header__source {
    display: none;
  }
</style>
<script>
  const dataList = [
    {
      appName: "General Task Solver",
      shortDesc:
        "Efficiently solve complex tasks using a divide and conquer algorithm.",
      desc: "General task solver is an agent that implements a powerful divide and conquer algorithm to address common computational problems. The agent intelligently assesses input tasks and, if deemed too complex, breaks them down into manageable sub-tasks. Each sub-task is then solved individually, ensuring a streamlined and efficient problem-solving process. It enhances performance and scalability, making it a versatile tool for various applications.",
      deviceList: "Command line, App, Webpage",
      img: "{{ base_url }}/assets/images/GeneralTaskSolver.png",
      url: "https://github.com/om-ai-lab/OmAgent/tree/main/examples/general_dnc",
    },
    {
      appName: "Video understanding",
      shortDesc:
        "Preprocess long videos and perform QA with human-like precision using Divide-and-Conquer and Rewinder tools.",
      desc: "Video Understanding is an agent that has capbility of handling hours-long videos and enable precise question-answering. By leveraging the Divide and Conquer (DnC) algorithm alongside the Rewinder tool, agent can intelligently navigate and analyze video content. This allows it to pinpoint and revisit specific segments, much like a human would. It excels in breaking down complex video data into manageable sections, providing accurate and context-aware answers to queries.",
      deviceList: "Command line, Webpage",
      img: "{{ base_url }}/assets/images/Videounderstanding.png",
      url: "https://github.com/om-ai-lab/OmAgent/tree/main/examples/video_understanding",
    },
    {
      appName: "Simple VQA",
      shortDesc:
        "A simple agent that enables users to ask questions about images and receive AI-powered responses",
      desc: "This agent is designed to process and respond to user queries about image content. The system combines image processing capabilities with natural language understanding to analyze visual information and generate relevant answers to user questions. The framework provides a complete pipeline from handling user input and image data to generating accurate, context-aware responses about visual content.",
      deviceList: "Command line, App, Webpage",
      img: "{{ base_url }}/assets/images/SimpleVQA.png",
      url: "https://github.com/om-ai-lab/OmAgent/tree/main/examples/step1_simpleVQA",
    },
    {
      appName: "Outfit with Switch",
      shortDesc:
        "A beginner-friendly demo agent that leverages OmAgent and Switch Worker features to provide personalized outfit recommendations based on user requests and optional weather conditions.",
      desc: "This demo agent showcases how to build an intelligent outfit recommendation system using OmAgent and Switch Worker capabilities. The agent processes user clothing requests and optionally incorporates real-time weather data into its recommendations based on context analysis. Using a switch-case mechanism, it dynamically decides whether to fetch weather information, making the recommendation process more contextually aware and efficient. The agent serves as an excellent starting point for understanding how to implement conditional workflows and integrate external data sources in OmAgent-based applications.",
      deviceList: "Command line, App, Webpage",
      img: "{{ base_url }}/assets/images/OutfitwithSwitch.png",
      url: "https://github.com/om-ai-lab/OmAgent/tree/main/examples/step2_outfit_with_switch",
    },
    {
      appName: "Outfit with Loop",
      shortDesc:
        "A beginner-friendly demo agent that leverages OmAgent and Loop features to provide interactive, weather-aware outfit recommendations based on user input and preferences.",
      desc: "This demo agent showcases how to build an interactive outfit recommendation system using OmAgent and Loop Worker capabilities. The agent starts by accepting an initial clothing item image and engages users in a dynamic Q&A session to understand their preferences and context. It incorporates real-time weather data from the user's location to ensure weather-appropriate suggestions. Through an iterative loop process, the agent refines its understanding until it has gathered sufficient information to provide personalized outfit recommendations that consider all collected factors.",
      deviceList: "Command line, App, Webpage",
      img: "{{ base_url }}/assets/images/OutfitwithLoop.png",
      url: "https://github.com/om-ai-lab/OmAgent/tree/main/examples/step3_outfit_with_loop",
    },
    {
      appName: "Outfit with LTM",
      shortDesc:
        "This agent showcases how to build an outfit recommendation agent using OmAgent framework with long-term memory capabilities, where it stores clothing images and provides personalized outfit suggestions based on user preferences.",
      desc: "This demo illustrates how to create an entry-level outfit recommendation system using the OmAgent framework with long-term memory (LTM) functionality. The agent consists of two main workflows: one for storing and indexing clothing images in a long-term memory database, and another for providing interactive outfit recommendations. Through conversation, the agent gathers user preferences and context (like weather conditions), then leverages its stored clothing database to generate personalized outfit suggestions. The system demonstrates practical implementation of persistent memory in AI agents while providing a useful real-world application.",
      deviceList: "Command line, App, Webpage",
      img: "{{ base_url }}/assets/images/OutfitwithLTM.png",
      url: "https://github.com/om-ai-lab/OmAgent/tree/main/examples/step4_outfit_with_ltm",
    },
  ];

  window.onload = function () {
    const container = document.querySelector(".container");
    const popup = document.getElementById("popup");
    const overlay = document.getElementById("overlay");
    const tryBtn = document.getElementById("tryBtn");

    // Function to open the popup
    function openPopup(itemValue) {
      popup.style.display = "block";
      overlay.style.display = "block";
      document.querySelector(".popup_title").textContent = itemValue.appName;
      document.querySelector(".popup_cont_img").src = itemValue.img;
      document.querySelector(".cont_info_desc").textContent = itemValue.desc;
      document.querySelector(".cont_info_device").textContent =
        itemValue.deviceList;
      document.querySelector(".try_btn").onclick = function () {
        window.open(itemValue.url, "_blank");
      };
      document.querySelector(".share_btn").onclick = function () {
        const text = encodeURIComponent(itemValue.appName);
        const url = encodeURIComponent(window.location.href);
        const hashtags = "AI agent, Agent framework,multimodel";
        const twitterUrl = `https://twitter.com/intent/tweet?text=${text}&url=${url}&hashtags=${hashtags}`;
        window.open(twitterUrl, "_blank");
      };
    }

    // Function to close the popup
    function closePopup() {
      popup.style.display = "none";
      overlay.style.display = "none";
    }

    container.innerHTML = "";
    dataList.forEach((item, index) => {
      const itemElement = document.createElement("div");
      itemElement.className = "item";
      itemElement.setAttribute("data-item", JSON.stringify(item));
      itemElement.id = `openPopupButton_${index}`;

      itemElement.innerHTML = `
        <img src="${item.img}" alt="" class="item_img" />
        <div class="item_title">${item.appName}</div>
        <div class="item_desc">${item.shortDesc}</div>
      `;

      itemElement.addEventListener("click", function () {
        const itemValue = JSON.parse(this.getAttribute("data-item"));
        openPopup(itemValue);
      });

      container.appendChild(itemElement);
    });

    overlay.addEventListener("click", closePopup);
  };
</script>
<section class="mdx-container">
  <div class="container_head">
    <img
      src="{{ base_url }}/assets/images/bg.png"
      alt=""
      class="container_head_img"
    />
    <div class="mdx__content">
      <div class="mdx_title">OmAgent</div>
      <div class="mdx_subtitle">
        A Multimodal Native Agent Framework for Smart Devices and More
      </div>
    </div>
  </div>
  <div class="mdx_box">
    <div class="content_title">Software Development</div>
    <div class="container"></div>
  </div>

  <div id="popup" class="popup">
    <div class="popup_header">
      <div class="popup_title">title</div>
      <div class="popup_share">
        <span class="share_btn">Share</span>
        <div class="try_btn" id="tryBtn">Try Now</div>
      </div>
    </div>
    <div class="popup_content">
      <div class="cont_info">
        <div class="cont_info_title"></div>
        <div class="cont_info_desc"></div>
        <div class="cont_info_device"></div>
      </div>
      <img src="" class="popup_cont_img" alt="" />
    </div>
  </div>

  <div id="overlay" class="overlay"></div>
</section>
{% endblock %} {% block content %}{% endblock %} {% block footer %}{% endblock
%}
